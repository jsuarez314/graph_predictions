{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3748188-bbd1-4d55-948e-136c651ca970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas             as pd\n",
    "import numpy              as np\n",
    "import pylab              as pl\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1473484f-1f23-4c88-ac8b-917130d437bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': '20',\n",
    "          'figure.figsize': (10, 10),\n",
    "         'axes.labelsize': '20',\n",
    "         'axes.titlesize':'20',\n",
    "         'xtick.labelsize':'20',\n",
    "         'ytick.labelsize':'20'}\n",
    "pl.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4feab8-f1b6-4c99-b9ae-bbcdf11766b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 64)\n",
    "        self.conv2 = GCNConv(64, data.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8374735-b20b-42fc-a765-ddb7999f504c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['ID', 'X', 'Y', 'Z', 'MASS', 'ENVIRONMENT', 'ID_DELAUNAY_CONNECTIONS',\n",
       "        'N_DELAUNAY_CONNECTIONS', 'DIS_DELAUNAY_CONNECTIONS',\n",
       "        'AVDIS_DELAUNAY_CONNECTIONS', 'ID_DELAUNAY_FIRSTNEIGH_CONNECTIONS',\n",
       "        'N_DELAUNAY_FIRSTNEIGH_CONNECTIONS', 'ID_BSK_CONNECTIONS',\n",
       "        'N_BSK_CONNECTIONS', 'DIS_BSK_CONNECTIONS', 'AVDIS_BSK_CONNECTIONS',\n",
       "        'ID_BSK_FIRSTNEIGH_CONNECTIONS', 'N_BSK_FIRSTNEIGH_CONNECTIONS'],\n",
       "       dtype='object'),\n",
       " 17963)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['Peak','Filament','Sheet','Void']\n",
    "\n",
    "df = pd.read_pickle('./data/TCW_topological_dataset.pkl')\n",
    "idx = np.arange(len(df))\n",
    "df.keys(), len(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3511f6-01ce-4229-8e74-5734b1be7fbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Delaunay Features  || Delaunay Edges -> TWebEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7eee8f-8949-4239-bee7-05f3043c6406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16292/3889135373.py:5: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  edge_index = torch.tensor([A,B], dtype=torch.long) # Conecctions\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 39.59 GiB total capacity; 19.09 MiB already allocated; 10.19 MiB free; 22.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16292/3889135373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mlloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16292/3548845818.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    161\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                         self.improved, self.add_self_loops)\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, dtype)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             edge_index, tmp_edge_weight = add_remaining_self_loops(\n\u001b[0m\u001b[1;32m     57\u001b[0m                 edge_index, edge_weight, fill_value, num_nodes)\n\u001b[1;32m     58\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtmp_edge_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_weight, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mloop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mloop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 39.59 GiB total capacity; 19.09 MiB already allocated; 10.19 MiB free; 22.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "predictors = np.array(df[['N_DELAUNAY_CONNECTIONS','AVDIS_DELAUNAY_CONNECTIONS']], dtype=float)\n",
    "x = torch.tensor(predictors, dtype=torch.float)  #features\n",
    "A = np.concatenate([ np.zeros(len(c))+i for i, c in  enumerate(df['ID_DELAUNAY_CONNECTIONS']) ]).ravel()\n",
    "B = np.concatenate([ c for i, c in  enumerate(df['ID_DELAUNAY_CONNECTIONS']) ]).ravel()\n",
    "edge_index = torch.tensor([A,B], dtype=torch.long) # Conecctions\n",
    "target = np.array([ c for c in  df['ENVIRONMENT'] ])\n",
    "y = torch.tensor(target, dtype=torch.long)  #target\n",
    "data = Data(x=x, edge_index=edge_index, y=y, num_classes= len(np.unique(y)))\n",
    "ii_train = idx <=len(idx)*0.7\n",
    "train_mask = ii_train\n",
    "test_mask  = ~ii_train\n",
    "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = 'cpu'\n",
    "model = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "lloss = []\n",
    "lf1   = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    lloss.append(loss.cpu().data)\n",
    "    f1 = f1_score(data.y[data.train_mask].cpu().detach().numpy(), out[data.train_mask].cpu().argmax(dim=1).detach().numpy(), average='weighted')\n",
    "    lf1.append(f1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')    \n",
    "\n",
    "f1 = f1_score(data.y[data.test_mask].cpu().data, pred[data.test_mask].cpu(), average='weighted')\n",
    "print(f'f1_score: {f1:.4f}')\n",
    "\n",
    "fig = pl.figure(figsize=(14,7))\n",
    "pl.subplot(1,2,1)\n",
    "_ = pl.plot(lloss)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.subplot(1,2,2)\n",
    "_ = pl.plot(lf1)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('f1_score')\n",
    "\n",
    "classes = ['Peak','Filament','Sheet','Void']\n",
    "#------------ Confusion Matrix\n",
    "cm = confusion_matrix(np.array(data.y[data.test_mask].cpu().data), np.array(pred[data.test_mask].cpu().data))\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig= pl.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=pl.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.79)\n",
    "ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=classes, yticklabels=classes)\n",
    "ax.set_xlabel(\"Environment Predicted\",size=20)\n",
    "ax.set_ylabel(\"Environment True\",size=20)\n",
    "# ax.set_ylim(4-0.5, -0.5)\n",
    "\n",
    "pl.setp(ax.get_xticklabels(), rotation=15, size=12)\n",
    "pl.setp(ax.get_yticklabels(), rotation=45, size=12)\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = cm.max()/2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=20 , color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57b6b5-c393-4734-b972-35b06e2ed381",
   "metadata": {},
   "source": [
    "## Bsk Features  || Bsk Edges -> TWebEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b149b0-ce23-44b0-a719-d5ec1d2b90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.array(df[['N_BSK_CONNECTIONS','AVDIS_BSK_CONNECTIONS']], dtype=float)\n",
    "x = torch.tensor(predictors, dtype=torch.float)  #features\n",
    "A = np.concatenate([ np.zeros(len(c))+i for i, c in  enumerate(df['ID_BSK_CONNECTIONS']) ]).ravel()\n",
    "B = np.concatenate([ c for i, c in  enumerate(df['ID_BSK_CONNECTIONS']) ]).ravel()\n",
    "edge_index = torch.tensor([A,B], dtype=torch.long) # Conecctions\n",
    "target = np.array([ c for c in  df['ENVIRONMENT'] ])\n",
    "y = torch.tensor(target, dtype=torch.long)  #target\n",
    "data = Data(x=x, edge_index=edge_index, y=y, num_classes= len(np.unique(y)))\n",
    "ii_train = idx <=len(idx)*0.7\n",
    "train_mask = ii_train\n",
    "test_mask  = ~ii_train\n",
    "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = 'cpu'\n",
    "model = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "lloss = []\n",
    "lf1   = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    lloss.append(loss.cpu().data)\n",
    "    f1 = f1_score(data.y[data.train_mask].cpu().detach().numpy(), out[data.train_mask].cpu().argmax(dim=1).detach().numpy(), average='weighted')\n",
    "    lf1.append(f1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')    \n",
    "\n",
    "f1 = f1_score(data.y[data.test_mask].cpu().data, pred[data.test_mask].cpu(), average='weighted')\n",
    "print(f'f1_score: {f1:.4f}')\n",
    "\n",
    "fig = pl.figure(figsize=(14,7))\n",
    "pl.subplot(1,2,1)\n",
    "_ = pl.plot(lloss)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.subplot(1,2,2)\n",
    "_ = pl.plot(lf1)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('f1_score')\n",
    "\n",
    "classes = ['Peak','Filament','Sheet','Void']\n",
    "#------------ Confusion Matrix\n",
    "cm = confusion_matrix(np.array(data.y[data.test_mask].cpu().data), np.array(pred[data.test_mask].cpu().data))\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig= pl.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=pl.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.79)\n",
    "ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=classes, yticklabels=classes)\n",
    "ax.set_xlabel(\"Environment Predicted\",size=20)\n",
    "ax.set_ylabel(\"Environment True\",size=20)\n",
    "# ax.set_ylim(4-0.5, -0.5)\n",
    "\n",
    "pl.setp(ax.get_xticklabels(), rotation=15, size=12)\n",
    "pl.setp(ax.get_yticklabels(), rotation=45, size=12)\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = cm.max()/2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=20 , color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdbd6e6-54fe-4ad7-a808-4d90cfbe22c3",
   "metadata": {},
   "source": [
    "## Delaunay + Bsk Features  || Delaunay Edges -> TWebEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00cb84c-9522-4ea8-b500-d802cdab9e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.array(df[['N_DELAUNAY_CONNECTIONS','AVDIS_DELAUNAY_CONNECTIONS',\n",
    "                          'N_BSK_CONNECTIONS','AVDIS_BSK_CONNECTIONS']], dtype=float)\n",
    "x = torch.tensor(predictors, dtype=torch.float)  #features\n",
    "A = np.concatenate([ np.zeros(len(c))+i for i, c in  enumerate(df['ID_DELAUNAY_CONNECTIONS']) ]).ravel()\n",
    "B = np.concatenate([ c for i, c in  enumerate(df['ID_DELAUNAY_CONNECTIONS']) ]).ravel()\n",
    "edge_index = torch.tensor([A,B], dtype=torch.long) # Conecctions\n",
    "target = np.array([ c for c in  df['ENVIRONMENT'] ])\n",
    "y = torch.tensor(target, dtype=torch.long)  #target\n",
    "data = Data(x=x, edge_index=edge_index, y=y, num_classes= len(np.unique(y)))\n",
    "ii_train = idx <=len(idx)*0.7\n",
    "train_mask = ii_train\n",
    "test_mask  = ~ii_train\n",
    "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = 'cpu'\n",
    "model = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "lloss = []\n",
    "lf1   = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    lloss.append(loss.cpu().data)\n",
    "    f1 = f1_score(data.y[data.train_mask].cpu().detach().numpy(), out[data.train_mask].cpu().argmax(dim=1).detach().numpy(), average='weighted')\n",
    "    lf1.append(f1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')    \n",
    "\n",
    "f1 = f1_score(data.y[data.test_mask].cpu().data, pred[data.test_mask].cpu(), average='weighted')\n",
    "print(f'f1_score: {f1:.4f}')\n",
    "\n",
    "fig = pl.figure(figsize=(14,7))\n",
    "pl.subplot(1,2,1)\n",
    "_ = pl.plot(lloss)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.subplot(1,2,2)\n",
    "_ = pl.plot(lf1)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('f1_score')\n",
    "\n",
    "classes = ['Peak','Filament','Sheet','Void']\n",
    "#------------ Confusion Matrix\n",
    "cm = confusion_matrix(np.array(data.y[data.test_mask].cpu().data), np.array(pred[data.test_mask].cpu().data))\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig= pl.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=pl.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.79)\n",
    "ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=classes, yticklabels=classes)\n",
    "ax.set_xlabel(\"Environment Predicted\",size=20)\n",
    "ax.set_ylabel(\"Environment True\",size=20)\n",
    "# ax.set_ylim(4-0.5, -0.5)\n",
    "\n",
    "pl.setp(ax.get_xticklabels(), rotation=15, size=12)\n",
    "pl.setp(ax.get_yticklabels(), rotation=45, size=12)\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = cm.max()/2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=20 , color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2445892-a35c-4b22-bc6e-d44b9ef8126e",
   "metadata": {},
   "source": [
    "## Delaunay + Bsk Features  || Bsk Edges -> TWebEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b4d70-da5e-46a7-8577-ec4ef816c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.array(df[['N_DELAUNAY_CONNECTIONS','AVDIS_DELAUNAY_CONNECTIONS','N_BSK_CONNECTIONS','AVDIS_BSK_CONNECTIONS']], dtype=float)\n",
    "x = torch.tensor(predictors, dtype=torch.float)  #features\n",
    "A = np.concatenate([ np.zeros(len(c))+i for i, c in  enumerate(df['ID_BSK_CONNECTIONS']) ]).ravel()\n",
    "B = np.concatenate([ c for i, c in  enumerate(df['ID_BSK_CONNECTIONS']) ]).ravel()\n",
    "edge_index = torch.tensor([A,B], dtype=torch.long) # Conecctions\n",
    "target = np.array([ c for c in  df['ENVIRONMENT'] ])\n",
    "y = torch.tensor(target, dtype=torch.long)  #target\n",
    "data = Data(x=x, edge_index=edge_index, y=y, num_classes= len(np.unique(y)))\n",
    "ii_train = idx <=len(idx)*0.7\n",
    "train_mask = ii_train\n",
    "test_mask  = ~ii_train\n",
    "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = 'cpu'\n",
    "model = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "lloss = []\n",
    "lf1   = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    lloss.append(loss.cpu().data)\n",
    "    f1 = f1_score(data.y[data.train_mask].cpu().detach().numpy(), out[data.train_mask].cpu().argmax(dim=1).detach().numpy(), average='weighted')\n",
    "    lf1.append(f1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')    \n",
    "\n",
    "f1 = f1_score(data.y[data.test_mask].cpu().data, pred[data.test_mask].cpu(), average='weighted')\n",
    "print(f'f1_score: {f1:.4f}')\n",
    "\n",
    "fig = pl.figure(figsize=(14,7))\n",
    "pl.subplot(1,2,1)\n",
    "_ = pl.plot(lloss)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.subplot(1,2,2)\n",
    "_ = pl.plot(lf1)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('f1_score')\n",
    "\n",
    "classes = ['Peak','Filament','Sheet','Void']\n",
    "#------------ Confusion Matrix\n",
    "cm = confusion_matrix(np.array(data.y[data.test_mask].cpu().data), np.array(pred[data.test_mask].cpu().data))\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig= pl.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=pl.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.79)\n",
    "ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=classes, yticklabels=classes)\n",
    "ax.set_xlabel(\"Environment Predicted\",size=20)\n",
    "ax.set_ylabel(\"Environment True\",size=20)\n",
    "# ax.set_ylim(4-0.5, -0.5)\n",
    "\n",
    "pl.setp(ax.get_xticklabels(), rotation=15, size=12)\n",
    "pl.setp(ax.get_yticklabels(), rotation=45, size=12)\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = cm.max()/2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=20 , color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6629f1-9b5e-46ed-8179-b2af2122f60f",
   "metadata": {},
   "source": [
    "##  Bsk Features  || Delaunay Edges -> TWebEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c4dce-6fa3-4369-a44a-6a959aa812ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.array(df[['N_BSK_CONNECTIONS','AVDIS_BSK_CONNECTIONS']], dtype=float)\n",
    "x = torch.tensor(predictors, dtype=torch.float)  #features\n",
    "A = np.concatenate([ np.zeros(len(c))+i for i, c in  enumerate(df['ID_DELAUNAY_CONNECTIONS']) ]).ravel()\n",
    "B = np.concatenate([ c for i, c in  enumerate(df['ID_DELAUNAY_CONNECTIONS']) ]).ravel()\n",
    "edge_index = torch.tensor([A,B], dtype=torch.long) # Conecctions\n",
    "target = np.array([ c for c in  df['ENVIRONMENT'] ])\n",
    "y = torch.tensor(target, dtype=torch.long)  #target\n",
    "data = Data(x=x, edge_index=edge_index, y=y, num_classes= len(np.unique(y)))\n",
    "ii_train = idx <=len(idx)*0.7\n",
    "train_mask = ii_train\n",
    "test_mask  = ~ii_train\n",
    "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = 'cpu'\n",
    "model = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "lloss = []\n",
    "lf1   = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    lloss.append(loss.cpu().data)\n",
    "    f1 = f1_score(data.y[data.train_mask].cpu().detach().numpy(), out[data.train_mask].cpu().argmax(dim=1).detach().numpy(), average='weighted')\n",
    "    lf1.append(f1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')    \n",
    "\n",
    "f1 = f1_score(data.y[data.test_mask].cpu().data, pred[data.test_mask].cpu(), average='weighted')\n",
    "print(f'f1_score: {f1:.4f}')\n",
    "\n",
    "fig = pl.figure(figsize=(14,7))\n",
    "pl.subplot(1,2,1)\n",
    "_ = pl.plot(lloss)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.subplot(1,2,2)\n",
    "_ = pl.plot(lf1)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('f1_score')\n",
    "\n",
    "classes = ['Peak','Filament','Sheet','Void']\n",
    "#------------ Confusion Matrix\n",
    "cm = confusion_matrix(np.array(data.y[data.test_mask].cpu().data), np.array(pred[data.test_mask].cpu().data))\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig= pl.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=pl.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.79)\n",
    "ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=classes, yticklabels=classes)\n",
    "ax.set_xlabel(\"Environment Predicted\",size=20)\n",
    "ax.set_ylabel(\"Environment True\",size=20)\n",
    "# ax.set_ylim(4-0.5, -0.5)\n",
    "\n",
    "pl.setp(ax.get_xticklabels(), rotation=15, size=12)\n",
    "pl.setp(ax.get_yticklabels(), rotation=45, size=12)\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = cm.max()/2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=20 , color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2fbbe-412b-4a6f-8be7-2da50c8c1f3d",
   "metadata": {},
   "source": [
    "##  Delaunay Features  || Bsk Edges -> TWebEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6f47c-d47f-4ebc-9ffe-8034adbd5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.array(df[['N_DELAUNAY_CONNECTIONS','AVDIS_DELAUNAY_CONNECTIONS']], dtype=float)\n",
    "x = torch.tensor(predictors, dtype=torch.float)  #features\n",
    "A = np.concatenate([ np.zeros(len(c))+i for i, c in  enumerate(df['ID_BSK_CONNECTIONS']) ]).ravel()\n",
    "B = np.concatenate([ c for i, c in  enumerate(df['ID_BSK_CONNECTIONS']) ]).ravel()\n",
    "edge_index = torch.tensor([A,B], dtype=torch.long) # Conecctions\n",
    "target = np.array([ c for c in  df['ENVIRONMENT'] ])\n",
    "y = torch.tensor(target, dtype=torch.long)  #target\n",
    "data = Data(x=x, edge_index=edge_index, y=y, num_classes= len(np.unique(y)))\n",
    "ii_train = idx <=len(idx)*0.7\n",
    "train_mask = ii_train\n",
    "test_mask  = ~ii_train\n",
    "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = 'cpu'\n",
    "model = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "lloss = []\n",
    "lf1   = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    lloss.append(loss.cpu().data)\n",
    "    f1 = f1_score(data.y[data.train_mask].cpu().detach().numpy(), out[data.train_mask].cpu().argmax(dim=1).detach().numpy(), average='weighted')\n",
    "    lf1.append(f1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')    \n",
    "\n",
    "f1 = f1_score(data.y[data.test_mask].cpu().data, pred[data.test_mask].cpu(), average='weighted')\n",
    "print(f'f1_score: {f1:.4f}')\n",
    "\n",
    "fig = pl.figure(figsize=(14,7))\n",
    "pl.subplot(1,2,1)\n",
    "_ = pl.plot(lloss)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.subplot(1,2,2)\n",
    "_ = pl.plot(lf1)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('f1_score')\n",
    "\n",
    "classes = ['Peak','Filament','Sheet','Void']\n",
    "#------------ Confusion Matrix\n",
    "cm = confusion_matrix(np.array(data.y[data.test_mask].cpu().data), np.array(pred[data.test_mask].cpu().data))\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig= pl.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=pl.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.79)\n",
    "ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=classes, yticklabels=classes)\n",
    "ax.set_xlabel(\"Environment Predicted\",size=20)\n",
    "ax.set_ylabel(\"Environment True\",size=20)\n",
    "# ax.set_ylim(4-0.5, -0.5)\n",
    "\n",
    "pl.setp(ax.get_xticklabels(), rotation=15, size=12)\n",
    "pl.setp(ax.get_yticklabels(), rotation=45, size=12)\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = cm.max()/2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=20 , color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13209080-4c52-4964-bd13-f5ee5ac10c38",
   "metadata": {},
   "source": [
    "## First Neighbors in second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9496e44-8c33-49d8-a8c7-cfeaf7faf506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_fn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 128)\n",
    "        self.conv2 = GCNConv(128, data.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_index_fn = data.x, data.edge_index, data.edge_index_fn\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index_fn)        \n",
    "        \n",
    "        return F.log_softmax(x, dim=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be852c6-883c-4e28-a8b7-26ad04bd4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.array(df[['N_DELAUNAY_CONNECTIONS','AVDIS_DELAUNAY_CONNECTIONS','N_BSK_CONNECTIONS','AVDIS_BSK_CONNECTIONS']], dtype=float)\n",
    "x = torch.tensor(predictors, dtype=torch.float)  #features\n",
    "\n",
    "A = np.concatenate([ np.zeros(len(c))+i for i, c in  enumerate(df['ID_DELAUNAY_CONNECTIONS']) ]).ravel()\n",
    "B = np.concatenate([ c for i, c in  enumerate(df['ID_DELAUNAY_CONNECTIONS']) ]).ravel()\n",
    "edge_index = torch.tensor([A,B], dtype=torch.long) # Conecctions\n",
    "\n",
    "A = np.concatenate([ np.zeros(len(c))+B[i] for i, c in  enumerate(df['ID_DELAUNAY_FIRSTNEIGH_CONNECTIONS']) ]).ravel()\n",
    "# A = np.concatenate([ np.zeros(len(c))+ i for i, c in  enumerate(df['ID_DELAUNAY_FIRSTNEIGH_CONNECTIONS']) ]).ravel()\n",
    "B = np.concatenate([ c for i, c in  enumerate(df['ID_DELAUNAY_FIRSTNEIGH_CONNECTIONS']) ]).ravel()\n",
    "edge_index_fn = torch.tensor([A,B], dtype=torch.long) # Conecctions\n",
    "\n",
    "\n",
    "target = np.array([ c for c in  df['ENVIRONMENT'] ])\n",
    "y = torch.tensor(target, dtype=torch.long)  #target\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, y=y, num_classes= len(np.unique(y)), edge_index_fn=edge_index_fn )\n",
    "\n",
    "ii_train = idx <=len(idx)*0.7\n",
    "train_mask = ii_train\n",
    "test_mask  = ~ii_train\n",
    "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = 'cpu'\n",
    "model = GCN_fn().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "lloss = []\n",
    "lf1   = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    lloss.append(loss.cpu().data)\n",
    "    f1 = f1_score(data.y[data.train_mask].cpu().detach().numpy(), out[data.train_mask].cpu().argmax(dim=1).detach().numpy(), average='weighted')\n",
    "    lf1.append(f1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')    \n",
    "\n",
    "f1 = f1_score(data.y[data.test_mask].cpu().data, pred[data.test_mask].cpu(), average='weighted')\n",
    "print(f'f1_score: {f1:.4f}')\n",
    "\n",
    "fig = pl.figure(figsize=(14,7))\n",
    "pl.subplot(1,2,1)\n",
    "_ = pl.plot(lloss)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.subplot(1,2,2)\n",
    "_ = pl.plot(lf1)\n",
    "pl.xlabel('epoch')\n",
    "pl.ylabel('f1_score')\n",
    "\n",
    "classes = ['Peak','Filament','Sheet','Void']\n",
    "#------------ Confusion Matrix\n",
    "cm = confusion_matrix(np.array(data.y[data.test_mask].cpu().data), np.array(pred[data.test_mask].cpu().data))\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig= pl.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=pl.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.79)\n",
    "ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=classes, yticklabels=classes)\n",
    "ax.set_xlabel(\"Environment Predicted\",size=20)\n",
    "ax.set_ylabel(\"Environment True\",size=20)\n",
    "# ax.set_ylim(4-0.5, -0.5)\n",
    "\n",
    "pl.setp(ax.get_xticklabels(), rotation=15, size=12)\n",
    "pl.setp(ax.get_yticklabels(), rotation=45, size=12)\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = cm.max()/2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=20 , color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90ab10-3750-4f60-9de5-1283718237be",
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a950725-a61c-4efd-99f5-3022867e4258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
